{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "lookup candidate entities and classes\n",
    "\"\"\"\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import argparse\n",
    "\n",
    "current_path = os.getcwd()\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\n",
    "    '--input_dir',\n",
    "    type=str,\n",
    "    default=os.path.join(current_path, 'data'),\n",
    "    help='Directory of input/output')\n",
    "parser.add_argument(\n",
    "    '--file_type',\n",
    "    type=str,\n",
    "    default='csv',\n",
    "    help='File type')\n",
    "\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "# if not os.path.exists(FLAGS.input_dir):\n",
    "#     os.mkdir(FLAGS.input_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the csv files from the input directory\n",
    "def get_data_files(data_folder):\n",
    "    \"\"\"\n",
    "    A function used to get all the csv files from the input directory\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    data_folder : str\n",
    "        the folder within  the working directory where the data is located\n",
    "    \"\"\"\n",
    "\n",
    "    files = [] # a list of all filenames, including file extensions, that contain data\n",
    "    csv_files = [] # same list as above but without the file extension\n",
    "\n",
    "    # Get the list of files\n",
    "    files = [f for f in os.listdir(FLAGS.input_dir+data_folder) if os.path.isfile(os.path.join(FLAGS.input_dir+data_folder, f))]\n",
    "    csv_files = [f.replace(\".csv\",\"\") for f in os.listdir(FLAGS.input_dir+data_folder) if os.path.isfile(os.path.join(FLAGS.input_dir+data_folder, f))]\n",
    "    \n",
    "    return csv_files\n",
    "\n",
    "def get_target_cta_columns(target_config_file, csv_files, filter_col = True):\n",
    "    \"\"\"\n",
    "    A function used to get which columns from the csv files need to be considered for the CTA. This is a subset of the file columns ignoring anything that is not an entity\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    target_config_file : str\n",
    "        the file that contains the target column indices for each file\n",
    "    csv_files : list\n",
    "        the list of csv files that have the tabular data\n",
    "    filter_col : boolean\n",
    "        a flag to indicate whether we should narrow down the reading of the columns to only those targeted for the CTA task\n",
    "    \"\"\"\n",
    "   \n",
    "    target_col_file = os.path.join(FLAGS.input_dir, target_config_file)\n",
    "    df_target_col = pd.read_csv(target_col_file,header=None, names=['filename','column_index'])\n",
    "    \n",
    "    # filter to only those files that are included in the csv_files\n",
    "    df_target_col = df_target_col.loc[df_target_col['filename'].isin(csv_files)]\n",
    "    \n",
    "    # collapse all rows pertaining to the same file into one key value pair. The key is the filename and the value is the list with the column indices that should be considered\n",
    "    # dict_target = {'CTRL_DBP_GEO_european_countries_capital_populated_cities': [0, 1, 2]}\n",
    "    dict_target = dict()\n",
    "    \n",
    "    for index,row in df_target_col.iterrows():\n",
    "        \n",
    "        # is this is the first row with this file create the key\n",
    "        if row['filename'] not in dict_target:\n",
    "            dict_target[row['filename']]= []\n",
    "            \n",
    "        # append the new target column to the target column list for that file\n",
    "        if filter_col:\n",
    "            dict_target[row['filename']].append(row['column_index'])\n",
    "    \n",
    "    return dict_target\n",
    "\n",
    "# Get the list of csv files with tabular data\n",
    "csv_files = get_data_files('\\lite')\n",
    "# csv_files = get_data_files('\\\\tables_full')\n",
    "\n",
    "# Get the columns we need to consider for the CTA task\n",
    "dict_target_col = get_target_cta_columns('CTA_DBP_Round1_Targets.csv', csv_files,True)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = list()\n",
    "data_folder = '\\lite'\n",
    "has_header_row = True\n",
    "\n",
    "for file in dict_target_col:\n",
    "    element = dict()\n",
    "    element['filename'] = file\n",
    "    df_data = pd.DataFrame()\n",
    "    df_title = pd.DataFrame()\n",
    "    \n",
    "    \n",
    "    \n",
    "    filename = file + '.' + FLAGS.file_type\n",
    "    tab_data_file = os.path.join(FLAGS.input_dir + data_folder, filename)\n",
    "      \n",
    "    # read the file data in a dataframe. Also read the column titles if we need to use them\n",
    "    if len(dict_target_col[file])>0:\n",
    "        if has_header_row:\n",
    "            df_data = pd.read_csv(tab_data_file,header=None, skiprows=[0], usecols=dict_target_col[file])\n",
    "            df_title = pd.read_csv(tab_data_file,header=None, usecols=dict_target_col[file], nrows = 1)\n",
    "        else:\n",
    "            df_data = pd.read_csv(tab_data_file,header=None, usecols=dict_target_col[file])\n",
    "    else:\n",
    "        if has_header_row:\n",
    "            df_data = pd.read_csv(tab_data_file,header=None, skiprows=[0])\n",
    "            df_title = pd.read_csv(tab_data_file,header=None, nrows = 1)\n",
    "        else:\n",
    "            df_data = pd.read_csv(tab_data_file,header=None)\n",
    "\n",
    "    # add the column headers to the data dictionary\n",
    "    try:\n",
    "        element['column_titles'] = list(df_title.iloc[0,:])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    file_element = dict()\n",
    "    for column in df_data.columns:\n",
    "        file_element[column] = list(set(df_data[column]))\n",
    "    element['data'] = file_element\n",
    "    \n",
    "    element['dataframe'] = df_data    \n",
    "    data.append(element)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['country', 'capital', 'most_populated_city']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]['data'][2]\n",
    "data[1]['column_titles']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['Serbia',\n",
       "  'Georgia',\n",
       "  'France',\n",
       "  'Montenegro',\n",
       "  'Latvia',\n",
       "  'Norway',\n",
       "  'Cyprus',\n",
       "  'Greece',\n",
       "  'Kazakhstan',\n",
       "  'Hungary',\n",
       "  'Slovakia',\n",
       "  'Bosnia and Herzegovina',\n",
       "  'Bulgaria',\n",
       "  'Armenia',\n",
       "  'Moldova',\n",
       "  'Denmark',\n",
       "  'Poland',\n",
       "  'Sweden',\n",
       "  'Босна и Херцеговина',\n",
       "  'Ukraine',\n",
       "  'Crna Gora',\n",
       "  'San Marino',\n",
       "  'Spain',\n",
       "  'Lithuania',\n",
       "  'Liechtenstein',\n",
       "  'Republika Srbija',\n",
       "  'Konungariket Sverige',\n",
       "  'Belarus',\n",
       "  'Република Србија',\n",
       "  'Црна Гора',\n",
       "  'Romania',\n",
       "  'Andorra',\n",
       "  'Republic of Macedonia',\n",
       "  'Italy',\n",
       "  'Estonia',\n",
       "  'Switzerland',\n",
       "  'Croatia',\n",
       "  'Kosovo',\n",
       "  'Slovenia',\n",
       "  'Bosna i Hercegovina',\n",
       "  'Malta',\n",
       "  'United Kingdom',\n",
       "  'the Czech Republic',\n",
       "  'Austria',\n",
       "  'Azerbaijan',\n",
       "  'Turkey'],\n",
       " 1: ['VVaduzz',\n",
       "  'Zagrebbb',\n",
       "  'Beograd / Београдд',\n",
       "  'Chiișinău',\n",
       "  'Rīga',\n",
       "  'Prahaaa',\n",
       "  'Roma Capitallee',\n",
       "  'Skopjee',\n",
       "  'City of San Marrino',\n",
       "  'Belgradee',\n",
       "  'Baakı',\n",
       "  'City of Zagrebb',\n",
       "  'Град Скоопје',\n",
       "  'Budapesttt',\n",
       "  'Soofia',\n",
       "  'Rommaa',\n",
       "  'City of Belgrade',\n",
       "  'Capital City of Budapesttt',\n",
       "  'Baku',\n",
       "  'Budaapest',\n",
       "  'Bernee',\n",
       "  'Madriidd',\n",
       "  'Skopjeee',\n",
       "  'Асттана',\n",
       "  'Budapest főváross',\n",
       "  'Bakkıı',\n",
       "  'MMinskk',\n",
       "  'Bernn',\n",
       "  'Wienn',\n",
       "  'Vilniius',\n",
       "  'Sarajevvoo',\n",
       "  'Софияя',\n",
       "  'City of Pristina',\n",
       "  'Астанаа',\n",
       "  'City  of Pristina',\n",
       "  'Bucureștii',\n",
       "  'Saraajevo',\n",
       "  'Скопје',\n",
       "  'Podgoricaa',\n",
       "  'თბილისიი',\n",
       "  'Pristinaa',\n",
       "  'Latin:Ursaria',\n",
       "  'Град Скопјее',\n",
       "  'Il-Belt Vallettaa',\n",
       "  'Parisss',\n",
       "  'Sofiaaa',\n",
       "  'Poddgoricaa',\n",
       "  'Praaha',\n",
       "  'Podgorica',\n",
       "  'ქუთაისიიი',\n",
       "  'Warssaww',\n",
       "  'Kievvv',\n",
       "  'Nicosiaa',\n",
       "  'Sarajevooo',\n",
       "  'Londonnn',\n",
       "  'Madrridd',\n",
       "  'Соффияя',\n",
       "  'Yeerevan',\n",
       "  'Rīgaaa',\n",
       "  'Град Скопје',\n",
       "  'Beograd / Београддд',\n",
       "  'Beograd  / Бееоград',\n",
       "  'PPrague',\n",
       "  'Ciity  of Podgorica',\n",
       "  'Andorra la Vellaaa',\n",
       "  'Sarajeevoo',\n",
       "  'Rome',\n",
       "  'Città di San Marinooo',\n",
       "  'BBeograd / Београд',\n",
       "  'Belgradde',\n",
       "  'Stockholmm',\n",
       "  'Valletta',\n",
       "  'Viennaaa',\n",
       "  'Prahaa',\n",
       "  'Bakuu',\n",
       "  'Tallinnn',\n",
       "  'Сарајевооо',\n",
       "  'Athenss',\n",
       "  'Wien',\n",
       "  'Astanaa',\n",
       "  'Belgradeee',\n",
       "  'City of Podgoricaa',\n",
       "  'Stockholmmm',\n",
       "  'Ankkara',\n",
       "  'BBucharestt',\n",
       "  'City of Skopje',\n",
       "  'Stockhollm',\n",
       "  'City of Zagreb',\n",
       "  'Beelgrade',\n",
       "  'Stockkhholm',\n",
       "  'City of Podgoricaaa',\n",
       "  'Copenhagennn',\n",
       "  'Pristinaaa',\n",
       "  'Сарајево',\n",
       "  'Kutaaisi',\n",
       "  'Ankarraa',\n",
       "  'Αθήνα',\n",
       "  'Valleettta',\n",
       "  'Сарајевоо',\n",
       "  'Skopje',\n",
       "  'Hllavní měssto Praha',\n",
       "  'Budapest fővároos',\n",
       "  'Yerevann',\n",
       "  'LLjubljana',\n",
       "  'Beograd / Београд',\n",
       "  'SSarajevo',\n",
       "  'City of Skopjjee',\n",
       "  'Miasto  stołeczne Warszawaa',\n",
       "  'City of Podggoricaa',\n",
       "  'City of Belgradee',\n",
       "  'МінскМинскк',\n",
       "  'City of Bellgradee',\n",
       "  'Vienna',\n",
       "  'Երրևան',\n",
       "  'Podgorricaa',\n",
       "  'Riga',\n",
       "  'Capital City of Warsawww',\n",
       "  'Hlavní město Prahaa',\n",
       "  'Poodgoorica',\n",
       "  'Latin:Ursariaaa',\n",
       "  'Osloo',\n",
       "  'Երևաանն',\n",
       "  'Sarajevo',\n",
       "  'Il-Belt Vallettaaa',\n",
       "  'Minsk',\n",
       "  'Budapest fővárosss',\n",
       "  'Belgrade',\n",
       "  'City of Belgraade',\n",
       "  'Nicosiia',\n",
       "  'Скопјее',\n",
       "  'Warszawa',\n",
       "  'City of Podgorica',\n",
       "  'Tbilisiii',\n",
       "  'МінскМинск',\n",
       "  'Capital City of Budapestt',\n",
       "  'Praguee',\n",
       "  'City of Skoppjee',\n",
       "  'Rigaaa',\n",
       "  'Bratislava',\n",
       "  'Zagrebb'],\n",
       " 2: ['Hlavní město Praha',\n",
       "  'Tuzla',\n",
       "  'Korzeniew',\n",
       "  'Rīga',\n",
       "  'Pristina',\n",
       "  'Алматы',\n",
       "  'Carei',\n",
       "  'Almaty',\n",
       "  'Kharkiv (Харків)',\n",
       "  'Арачиново',\n",
       "  'Luzern',\n",
       "  'Arinsal',\n",
       "  'Sofia',\n",
       "  'Latin:Ursaria',\n",
       "  'Nendeln',\n",
       "  'Haraçinë',\n",
       "  'Kaunas',\n",
       "  'Prague',\n",
       "  'Zagreb',\n",
       "  'Bergen',\n",
       "  'Palić',\n",
       "  'Praha',\n",
       "  'Poitiers',\n",
       "  'Metropolitan City of Rome Capital',\n",
       "  'Gothenburg',\n",
       "  'Vienna',\n",
       "  'Палић',\n",
       "  'Thessaloniki',\n",
       "  'Madrid',\n",
       "  'Kharkov (Харьков)',\n",
       "  'City of Zagreb',\n",
       "  'Podgorica',\n",
       "  'Riga',\n",
       "  'Malé Dvorníky',\n",
       "  'Тузла',\n",
       "  'Երևան',\n",
       "  'Ljubljana',\n",
       "  'Capital City of Budapest',\n",
       "  'Göteborg',\n",
       "  'Batumi',\n",
       "  'İstanbul',\n",
       "  'Λεμεσός / Limasol',\n",
       "  'Minsk',\n",
       "  'Gəncə',\n",
       "  'Budapest főváros',\n",
       "  'Ganja',\n",
       "  'София',\n",
       "  'Chișinău',\n",
       "  'Ħal Qormi',\n",
       "  'Cwmffrwd',\n",
       "  'Aračinovo / Arachinovo',\n",
       "  'Budapest',\n",
       "  'Istanbul',\n",
       "  'City of Podgorica',\n",
       "  'Qormi',\n",
       "  'Tallinn',\n",
       "  'City of Pristina',\n",
       "  'МінскМинск',\n",
       "  'Limassol',\n",
       "  'Odense',\n",
       "  'Yerevan',\n",
       "  'Wien',\n",
       "  'Dogana']}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CTRL_DBP_GEO_european_countries_capital_populated_cities',\n",
       " 'CTRL_DBP_GEO_european_countries_capital_populated_cities_NOISE2',\n",
       " 'CTRL_DBP_GEO_protected_areas',\n",
       " 'CTRL_DBP_GEO_protected_areas_NOISE2',\n",
       " 'CTRL_DBP_GEO_us_lakes - Copy',\n",
       " 'CTRL_DBP_GEO_us_lakes',\n",
       " 'CTRL_DBP_GEO_us_lakes_NOISE2']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lookup_resources(cell_text):\n",
    "    dbo_prefix = 'http://dbpedia.org/ontology/'\n",
    "    dbp_prefix = 'http://dbpedia.org/resource/'\n",
    "    entity_classes = dict()\n",
    "    cell_items = list()\n",
    "    cell_brackets = re.findall('\\((.*?)\\)', cell_text)\n",
    "    for cell_bracket in cell_brackets:\n",
    "        cell_text = cell_text.replace('(%s)' % cell_bracket, '')\n",
    "    cell_text = cell_text.strip()\n",
    "    if len(cell_text) > 2:\n",
    "        cell_items.append(cell_text)\n",
    "    for cell_bracket in cell_brackets:\n",
    "        if len(cell_bracket) > 2:\n",
    "            cell_items.append(cell_bracket.strip())\n",
    "    for cell_item in cell_items:\n",
    "        try:\n",
    "            lookup_url = 'http://lookup.dbpedia.org/api/search/KeywordSearch?MaxHits=2&QueryString=%s' % cell_item\n",
    "            lookup_res = requests.get(lookup_url)\n",
    "            root = ET.fromstring(lookup_res.content)\n",
    "            for child in root:\n",
    "                entity = child[1].text.split(dbp_prefix)[1]\n",
    "                classes = list()\n",
    "                for cc in child[3]:\n",
    "                    cls_URI = cc[1].text\n",
    "                    if dbo_prefix in cls_URI:\n",
    "                        classes.append(cls_URI.split(dbo_prefix)[1])\n",
    "                entity_classes[entity] = classes\n",
    "        except UnicodeDecodeError:\n",
    "            pass\n",
    "    return entity_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Aaron_River_Reservoir': ['Place',\n",
       "  'Dam',\n",
       "  'ArchitecturalStructure',\n",
       "  'Location',\n",
       "  'Infrastructure']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import re\n",
    "# import sparql\n",
    "import xml.etree.ElementTree as ET\n",
    "lookup_resources('Aaron River Reservoir')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "candidate_class = dict()\n",
    "\n",
    "for k in data[1]['data']:\n",
    "    candidate_class[k] = list([])\n",
    "    for i in data[1]['data'][k]:\n",
    "        lookup_resources(i)\n",
    "        candidate_class[k].append(lookup_resources(i))\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cell_text = 'Metropolitan City of Rome Capital'\n",
    "# cell_text = 'Limasol'\n",
    "\n",
    "# dbo_prefix = 'http://dbpedia.org/ontology/'\n",
    "# dbp_prefix = 'http://dbpedia.org/resource/'\n",
    "entity_classes = dict()\n",
    "cell_items = list()\n",
    "cell_brackets = re.findall('\\((.*?)\\)', cell_text)\n",
    "for cell_bracket in cell_brackets:\n",
    "    cell_text = cell_text.replace('(%s)' % cell_bracket, '')\n",
    "cell_text = cell_text.strip()\n",
    "if len(cell_text) > 2:\n",
    "    cell_items.append(cell_text)\n",
    "for cell_bracket in cell_brackets:\n",
    "    if len(cell_bracket) > 2:\n",
    "        cell_items.append(cell_bracket.strip())\n",
    "# for cell_item in cell_items:\n",
    "#     try:\n",
    "#         lookup_url = 'http://lookup.dbpedia.org/api/search/KeywordSearch?MaxHits=2&QueryString=%s' % cell_item\n",
    "#         lookup_res = requests.get(lookup_url)\n",
    "#         root = ET.fromstring(lookup_res.content)\n",
    "#         for child in root:\n",
    "#             entity = child[1].text.split(dbp_prefix)[1]\n",
    "#             classes = list()\n",
    "#             for cc in child[3]:\n",
    "#                 cls_URI = cc[1].text\n",
    "#                 if dbo_prefix in cls_URI:\n",
    "#                     classes.append(cls_URI.split(dbo_prefix)[1])\n",
    "#             entity_classes[entity] = classes\n",
    "#     except UnicodeDecodeError:\n",
    "#         pass\n",
    "# return entity_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Metropolitan City of Rome Capital']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'group'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-5c27ab605cda>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mre\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'(?<=abc)ef'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'abcdef'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'group'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "m = re.search('(?<=abc)ef', 'abcdef')\n",
    "m.group(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
